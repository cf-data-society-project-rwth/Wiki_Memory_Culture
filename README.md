# Wiki_Memory_Culture
Lab Project of Data &amp; Society - RWTH Aachen University

**Source Code** folder contains all the python source codes that we used to analyse Wiki memory culture.
- getSampleArticles.py is used to fetch top 1000 ranked Wikipedia articles of each month from July 2015 to Oct 2018
- standardDevAlgorithm.py, relativeMaximaAlgorithm.py and nearestNeighborAlgorithm.py are the three algorithms developed for peak detection of yearly events compiling the results in a csv format.
- translate.py is used to fetch the corresponding wikipedia article in the desired language by providing a list of English Wikipedia articles.
- visualization.py converts the csv format files into a histogram for the final results.
- visualization_of_category.py uses three different language csv result files as inputs and converts them into a histogram for comparison between the languages.

**result_files** folder contains all the csv format result files generated by the algorithm.
- The file is named based on the algorithm along with the factor/percentile and the Wikipedia language (empty for english, de for German and indos for Bahasa Indonesia) used. E.g. filename argrelmax_50.csv means the relativeMaxima algorithm is used for percentile 50 for English Wikipedia.

**list_of_articles** folder contains the list of articles fetched by the getSampleArticles.py file. Algorithms are executed on these files.

**graph** folder contains all the visualization graphs generated by the visualization.py and visualization_of_category.py files.
- The file is named based on the algorithm along with the factor/percentile and the Wikipedia language (empty for english, de for German and indos for Bahasa Indonesia) used. E.g. filename argrelmax_50.png means the relativeMaxima algorithm is used for percentile 50 for English Wikipedia.
